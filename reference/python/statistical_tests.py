#!/usr/bin/env python3
"""
å°å£²æ¥­ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆåˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
import json
import os
from pathlib import Path

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
plt.rcParams['font.family'] = ['Hiragino Sans', 'Yu Gothic', 'Meiryo', 'Takao', 'IPAexGothic', 'IPAPGothic', 'VL PGothic', 'Noto Sans CJK JP']

def load_data():
    """ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€"""
    data_path = Path(__file__).parent.parent / 'data' / 'for_python' / 'retail_data_with_ratios.csv'
    
    if not data_path.exists():
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {data_path}")
        return None
    
    df = pd.read_csv(data_path)
    print(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(df)}è¡Œ, {len(df.columns)}åˆ—")
    print(f"ğŸ™ï¸  éƒ½å¸‚: {', '.join(df['city'].unique())}")
    print(f"ğŸ“… å¹´æ¬¡: {', '.join(map(str, sorted(df['year'].unique())))}")
    
    return df

def descriptive_statistics(df):
    """è¨˜è¿°çµ±è¨ˆ"""
    print("\n=== è¨˜è¿°çµ±è¨ˆ ===")
    
    numeric_cols = ['establishments', 'employees', 'sales', 'salesArea', 
                   'salesAreaPerEmployee', 'employeesPerEstablishment', 
                   'salesPerEstablishment', 'salesPerEmployee']
    
    print("\nğŸ“Š å…¨ä½“çµ±è¨ˆ:")
    print(df[numeric_cols].describe().round(2))
    
    print("\nğŸ™ï¸  éƒ½å¸‚åˆ¥çµ±è¨ˆ:")
    for city in df['city'].unique():
        city_data = df[df['city'] == city]
        print(f"\n{city}:")
        print(city_data[numeric_cols].describe().round(2))

def time_series_analysis(df):
    """æ™‚ç³»åˆ—åˆ†æ"""
    print("\n=== æ™‚ç³»åˆ—åˆ†æ ===")
    
    # éƒ½å¸‚åˆ¥ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
    for city in df['city'].unique():
        city_data = df[df['city'] == city].sort_values('year')
        print(f"\nğŸ™ï¸  {city}ã®ãƒˆãƒ¬ãƒ³ãƒ‰:")
        
        # å„æŒ‡æ¨™ã®å¹´å¹³å‡æˆé•·ç‡è¨ˆç®—
        metrics = ['establishments', 'employees', 'sales', 'salesArea']
        
        for metric in metrics:
            values = city_data[metric].values
            years = city_data['year'].values
            
            if len(values) > 1:
                # ç·šå½¢å›å¸°ã§å‚¾å‘ã‚’è¨ˆç®—
                slope, intercept, r_value, p_value, std_err = stats.linregress(years, values)
                mean_value = np.mean(values)
                annual_change_rate = (slope / mean_value) * 100
                
                print(f"   {metric}: {annual_change_rate:+.2f}%/å¹´ (RÂ²={r_value**2:.3f}, p={p_value:.3f})")

def statistical_tests(df):
    """çµ±è¨ˆçš„æ¤œå®š"""
    print("\n=== çµ±è¨ˆçš„æ¤œå®š ===")
    
    # éƒ½å¸‚é–“æ¯”è¼ƒï¼ˆæœ€æ–°å¹´ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ï¼‰
    latest_year = df['year'].max()
    latest_data = df[df['year'] == latest_year]
    
    if len(latest_data) == 2:  # 2éƒ½å¸‚ã®æ¯”è¼ƒ
        city1_data = latest_data[latest_data['city'] == latest_data['city'].iloc[0]]
        city2_data = latest_data[latest_data['city'] == latest_data['city'].iloc[1]]
        
        city1_name = city1_data['city'].iloc[0]
        city2_name = city2_data['city'].iloc[0]
        
        print(f"\nğŸ™ï¸  {city1_name} vs {city2_name} ({latest_year}å¹´)")
        
        # ä¸»è¦æŒ‡æ¨™ã®æ¯”è¼ƒ
        metrics = ['establishments', 'employees', 'sales', 'salesPerEmployee']
        
        for metric in metrics:
            val1 = city1_data[metric].iloc[0]
            val2 = city2_data[metric].iloc[0]
            
            diff_pct = ((val2 - val1) / val1) * 100
            
            print(f"   {metric}: {city1_name}={val1:,.0f}, {city2_name}={val2:,.0f} ({diff_pct:+.1f}%)")
    
    # å¹´æ¬¡é–“ã®å¤‰åŒ–ã®æœ‰æ„æ€§æ¤œå®šï¼ˆå…¨ãƒ‡ãƒ¼ã‚¿ï¼‰
    print(f"\nğŸ“ˆ æ™‚ç³»åˆ—å¤‰åŒ–ã®åˆ†æ:")
    
    years = sorted(df['year'].unique())
    if len(years) >= 3:
        for metric in ['establishments', 'employees', 'sales']:
            # å„å¹´ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            year_groups = [df[df['year'] == year][metric].values for year in years]
            
            # ä¸€å…ƒé…ç½®åˆ†æ•£åˆ†æ
            f_stat, p_value = stats.f_oneway(*year_groups)
            
            print(f"   {metric}: F={f_stat:.3f}, p={p_value:.3f}")
            
            if p_value < 0.05:
                print(f"     â†’ å¹´æ¬¡é–“ã§æœ‰æ„å·®ã‚ã‚Š (p < 0.05)")
            else:
                print(f"     â†’ å¹´æ¬¡é–“ã§æœ‰æ„å·®ãªã— (p â‰¥ 0.05)")

def correlation_analysis(df):
    """ç›¸é–¢åˆ†æ"""
    print("\n=== ç›¸é–¢åˆ†æ ===")
    
    numeric_cols = ['establishments', 'employees', 'sales', 'salesArea']
    
    # ç›¸é–¢è¡Œåˆ—è¨ˆç®—
    corr_matrix = df[numeric_cols].corr()
    
    print("\nğŸ“Š ç›¸é–¢è¡Œåˆ—:")
    print(corr_matrix.round(3))
    
    # é«˜ã„ç›¸é–¢ã‚’æŒã¤ãƒšã‚¢ã‚’ç‰¹å®š
    print("\nğŸ” é«˜ã„ç›¸é–¢ã‚’æŒã¤æŒ‡æ¨™ãƒšã‚¢ (|r| > 0.7):")
    
    for i in range(len(numeric_cols)):
        for j in range(i+1, len(numeric_cols)):
            corr_val = corr_matrix.iloc[i, j]
            if abs(corr_val) > 0.7:
                print(f"   {numeric_cols[i]} - {numeric_cols[j]}: r = {corr_val:.3f}")

def create_visualizations(df):
    """å¯è¦–åŒ–ä½œæˆ"""
    print("\n=== å¯è¦–åŒ–ä½œæˆ ===")
    
    # çµæœä¿å­˜ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    figures_dir = Path(__file__).parent.parent / 'results' / 'figures'
    figures_dir.mkdir(parents=True, exist_ok=True)
    
    # 1. æ™‚ç³»åˆ—ãƒ—ãƒ­ãƒƒãƒˆ
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    fig.suptitle('å°å£²æ¥­æŒ‡æ¨™ã®æ™‚ç³»åˆ—å¤‰åŒ–', fontsize=16)
    
    metrics = ['establishments', 'employees', 'sales', 'salesArea']
    titles = ['äº‹æ¥­æ‰€æ•°', 'å¾“æ¥­è€…æ•°', 'è²©å£²é¡ï¼ˆç™¾ä¸‡å††ï¼‰', 'å£²å ´é¢ç©ï¼ˆã¡ï¼‰']
    
    for i, (metric, title) in enumerate(zip(metrics, titles)):
        ax = axes[i//2, i%2]
        
        for city in df['city'].unique():
            city_data = df[df['city'] == city].sort_values('year')
            ax.plot(city_data['year'], city_data[metric], marker='o', linewidth=2, label=city)
        
        ax.set_title(title)
        ax.set_xlabel('å¹´')
        ax.set_ylabel(title)
        ax.legend()
        ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(figures_dir / 'time_series.png', dpi=300, bbox_inches='tight')
    print(f"ğŸ“Š æ™‚ç³»åˆ—ã‚°ãƒ©ãƒ•ã‚’ä¿å­˜: {figures_dir / 'time_series.png'}")
    
    # 2. åŠ¹ç‡æ€§æŒ‡æ¨™ã®æ¯”è¼ƒ
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    fig.suptitle('åŠ¹ç‡æ€§æŒ‡æ¨™ã®æ¯”è¼ƒ', fontsize=16)
    
    efficiency_metrics = ['salesPerEmployee', 'salesPerEstablishment', 
                         'employeesPerEstablishment', 'salesAreaPerEmployee']
    efficiency_titles = ['å¾“æ¥­è€…1äººå½“ãŸã‚Šè²©å£²é¡', '1äº‹æ¥­æ‰€å½“ãŸã‚Šè²©å£²é¡', 
                        '1äº‹æ¥­æ‰€å½“ãŸã‚Šå¾“æ¥­è€…æ•°', 'å¾“æ¥­è€…1äººå½“ãŸã‚Šå£²å ´é¢ç©']
    
    for i, (metric, title) in enumerate(zip(efficiency_metrics, efficiency_titles)):
        ax = axes[i//2, i%2]
        
        for city in df['city'].unique():
            city_data = df[df['city'] == city].sort_values('year')
            ax.plot(city_data['year'], city_data[metric], marker='s', linewidth=2, label=city)
        
        ax.set_title(title)
        ax.set_xlabel('å¹´')
        ax.set_ylabel(title)
        ax.legend()
        ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(figures_dir / 'efficiency_metrics.png', dpi=300, bbox_inches='tight')
    print(f"ğŸ“Š åŠ¹ç‡æ€§æŒ‡æ¨™ã‚°ãƒ©ãƒ•ã‚’ä¿å­˜: {figures_dir / 'efficiency_metrics.png'}")
    
    # 3. ç›¸é–¢ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
    plt.figure(figsize=(10, 8))
    
    numeric_cols = ['establishments', 'employees', 'sales', 'salesArea']
    corr_matrix = df[numeric_cols].corr()
    
    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, 
                square=True, fmt='.3f', cbar_kws={'label': 'ç›¸é–¢ä¿‚æ•°'})
    plt.title('å°å£²æ¥­æŒ‡æ¨™é–“ã®ç›¸é–¢é–¢ä¿‚')
    
    plt.tight_layout()
    plt.savefig(figures_dir / 'correlation_heatmap.png', dpi=300, bbox_inches='tight')
    print(f"ğŸ“Š ç›¸é–¢ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚’ä¿å­˜: {figures_dir / 'correlation_heatmap.png'}")

def save_results(df):
    """åˆ†æçµæœã‚’ä¿å­˜"""
    print("\n=== åˆ†æçµæœä¿å­˜ ===")
    
    results_dir = Path(__file__).parent.parent / 'results' / 'tables'
    results_dir.mkdir(parents=True, exist_ok=True)
    
    # è©³ç´°çµ±è¨ˆã‚’CSVã§ä¿å­˜
    detailed_stats = df.groupby(['city', 'year']).agg({
        'establishments': 'first',
        'employees': 'first', 
        'sales': 'first',
        'salesArea': 'first',
        'salesPerEmployee': 'first',
        'salesPerEstablishment': 'first',
        'employeesPerEstablishment': 'first',
        'salesAreaPerEmployee': 'first'
    }).reset_index()
    
    detailed_stats.to_csv(results_dir / 'detailed_statistics.csv', 
                         index=False, encoding='utf-8-sig')
    print(f"ğŸ“„ è©³ç´°çµ±è¨ˆã‚’ä¿å­˜: {results_dir / 'detailed_statistics.csv'}")

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("=== å°å£²æ¥­ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆåˆ†æ (Python) ===\n")
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    df = load_data()
    if df is None:
        return
    
    # å„ç¨®åˆ†æå®Ÿè¡Œ
    descriptive_statistics(df)
    time_series_analysis(df)
    statistical_tests(df)
    correlation_analysis(df)
    create_visualizations(df)
    save_results(df)
    
    print("\nâœ… Pythonçµ±è¨ˆåˆ†æå®Œäº†!")

if __name__ == "__main__":
    main()